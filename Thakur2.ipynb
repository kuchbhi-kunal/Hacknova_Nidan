{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaG9uzaadUxY",
        "outputId": "fe632e1a-19b0-4fbb-9352-d4308d5e9c3b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "xStKSN9elWSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "rxoWBKfzGk87"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hLiyPw0ac_uv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Functionalities"
      ],
      "metadata": {
        "id": "ldRLIv54lbQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#Walkthrough\n",
        "for dirpath, dirnames, filenames in os.walk(\"/content/drive/MyDrive/Colab Data_Files/Thakur_Data\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}.\")"
      ],
      "metadata": {
        "id": "YHchi4vDgIPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f1fdf8-f9c1-4e56-f251-c5f7af4db6de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 5 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data.\n",
            "There are 2 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple.\n",
            "There are 4 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Train.\n",
            "There are 0 directories and 570 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Train/Apple___Apple_scab.\n",
            "There are 0 directories and 561 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Train/Apple___Black_rot.\n",
            "There are 0 directories and 239 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Train/Apple___Cedar_apple_rust.\n",
            "There are 0 directories and 1531 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Train/Apple___healthy.\n",
            "There are 4 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Test.\n",
            "There are 0 directories and 36 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Test/Apple___Cedar_apple_rust.\n",
            "There are 0 directories and 120 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Test/Apple___healthy.\n",
            "There are 0 directories and 60 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Test/Apple___Black_rot.\n",
            "There are 0 directories and 60 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Apple/Test/Apple___Apple_scab.\n",
            "There are 2 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn.\n",
            "There are 4 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Train.\n",
            "There are 0 directories and 877 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Train/Corn_(maize)___Northern_Leaf_Blight.\n",
            "There are 0 directories and 470 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Train/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot.\n",
            "There are 0 directories and 1042 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Train/Corn_(maize)___healthy.\n",
            "There are 0 directories and 1084 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Train/Corn_(maize)___Common_rust_.\n",
            "There are 4 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Test.\n",
            "There are 0 directories and 108 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Test/Corn_(maize)___Common_rust_.\n",
            "There are 0 directories and 108 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Test/Corn_(maize)___Northern_Leaf_Blight.\n",
            "There are 0 directories and 120 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Test/Corn_(maize)___healthy.\n",
            "There are 0 directories and 60 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Corn/Test/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot.\n",
            "There are 2 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes.\n",
            "There are 3 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes/Train.\n",
            "There are 0 directories and 375 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes/Train/Grape___healthy.\n",
            "There are 0 directories and 956 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes/Train/Grape___Leaf_blight_(Isariopsis_Leaf_Spot).\n",
            "There are 0 directories and 1120 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes/Train/Grape___Esca_(Black_Measles).\n",
            "There are 3 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes/Test.\n",
            "There are 0 directories and 120 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes/Test/Grape___Leaf_blight_(Isariopsis_Leaf_Spot).\n",
            "There are 0 directories and 132 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes/Test/Grape___Esca_(Black_Measles).\n",
            "There are 0 directories and 48 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Grapes/Test/Grape___healthy.\n",
            "There are 0 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/.ipynb_checkpoints.\n",
            "There are 2 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Log.\n",
            "There are 1 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Log/20230120-080424.\n",
            "There are 0 directories and 1 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Log/20230120-080424/train.\n",
            "There are 2 directories and 0 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Log/20230120-080505.\n",
            "There are 0 directories and 1 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Log/20230120-080505/train.\n",
            "There are 0 directories and 1 images in /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Log/20230120-080505/validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Walkthrough(data):\n",
        "  for dirpath, dirnames, filenames in os.walk(f\"/content/drive/MyDrive/Colab Data_Files/Thakur_Data/{data}\"):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}.\")"
      ],
      "metadata": {
        "id": "ThT9Sfx1lDAg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def veiw_random_image(target_dir,target_class):\n",
        "  #Set up target directory(We'll veiw images from here)\n",
        "  target_folder = target_dir + target_class\n",
        "\n",
        "  #Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder),1)\n",
        "  print(random_image)\n",
        "  print(random_image[0])\n",
        "  #Read in the image and plot it using matplotlib\n",
        "  img = mpimg.imread(target_folder + \"/\" +random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\");\n",
        "\n",
        "  print(f\"Image Shape: {img.shape}\") #Show the shape of image\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "0gjV0M5RqR_U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Veiw_batched_images(batch_Data,class_names):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for image_batch, labels_batch in batch_Data:\n",
        "      for i in range(12):\n",
        "          ax = plt.subplot(3, 4, i + 1)\n",
        "          plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "          plt.title(class_names[labels_batch[i]])\n",
        "          plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "zqha0_Re1rsB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "#Create a Function to build a TensorBoard CallBack\n",
        "def create_tensorboard_callback():\n",
        "  #Create a Log Directory to store Logs\n",
        "  logdir = os.path.join(\"/content/drive/MyDrive/Colab Data_Files/Thakur_Data/Log\",\n",
        "                        #Track The Logs whenever we run expirement i.e. joining it with datetime\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  \n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "8CU78oM2G2Zi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "_ss7KnNqniAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Data_Augmentation(data_path,IMG_SIZE = (256,256),BATCH_SIZE = 32):\n",
        "   # Set the seed\n",
        "  tf.random.set_seed(42)\n",
        "\n",
        "  # Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                    rotation_range=5,\n",
        "                                    width_shift_range=0.3,\n",
        "                                    height_shift_range=0.3,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=True,\n",
        "                                    channel_shift_range=0.4)\n",
        "  \n",
        "  valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Setup the train directories\n",
        "  train_dir = '/content/drive/MyDrive/Colab Data_Files/Thakur_Data/' + data_path + '/Train'\n",
        "  test_dir = '/content/drive/MyDrive/Colab Data_Files/Thakur_Data/' + data_path + '/Test'\n",
        "\n",
        "  # Import data from directories and turn it into batches\n",
        "  train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                                batch_size=BATCH_SIZE, # number of images to process at a time \n",
        "                                                target_size=IMG_SIZE, # convert all images to be 224 x 224\n",
        "                                                class_mode=\"categorical\", # type of problem we're working on\n",
        "                                                seed=42)\n",
        "  \n",
        "  valid_data = valid_datagen.flow_from_directory(test_dir,\n",
        "                                                batch_size=BATCH_SIZE, # number of images to process at a time \n",
        "                                                target_size=IMG_SIZE, # convert all images to be 224 x 224\n",
        "                                                class_mode=\"categorical\", # type of problem we're working on\n",
        "                                                seed=42)\n",
        "\n",
        "  return train_data,valid_data"
      ],
      "metadata": {
        "id": "SbARcZu1gzRc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apple"
      ],
      "metadata": {
        "id": "Iphh9CMrw6Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_Apple,val_Apple=Data_Augmentation('Apple')\n",
        "train_Apple,val_Apple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX-oF9Xjw5KN",
        "outputId": "8479ff7f-ba9d-4488-a980-81f8b693638a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2901 images belonging to 4 classes.\n",
            "Found 276 images belonging to 4 classes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<keras.preprocessing.image.DirectoryIterator at 0x7fca82ea77f0>,\n",
              " <keras.preprocessing.image.DirectoryIterator at 0x7fca82ea7a00>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE  = 32\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS = 3\n",
        "input_shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS)\n",
        "n_classes = 4\n",
        "\n",
        "model_Apple = models.Sequential([\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_Apple.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "0EBie0qrAPGt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Apple.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1kyhzbDCzNV",
        "outputId": "2bc50c30-de26-499a-97ca-454b56844573"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 183,812\n",
            "Trainable params: 183,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_Apple.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "KHEI6I5UDu2j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_Apple.fit(train_Apple,\n",
        "                        epochs=5,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        verbose=1,\n",
        "                        steps_per_epoch=len(train_Apple),\n",
        "                        validation_data=val_Apple,\n",
        "                        validation_steps=len(val_Apple))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE2v94LIEpLC",
        "outputId": "f46db51a-e7cf-429f-ac34-22a064277428"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "91/91 [==============================] - 756s 8s/step - loss: 1.1699 - accuracy: 0.5274 - val_loss: 1.2899 - val_accuracy: 0.4348\n",
            "Epoch 2/5\n",
            "91/91 [==============================] - 48s 532ms/step - loss: 0.9122 - accuracy: 0.5777 - val_loss: 0.8776 - val_accuracy: 0.6413\n",
            "Epoch 3/5\n",
            "91/91 [==============================] - 53s 584ms/step - loss: 0.7435 - accuracy: 0.6774 - val_loss: 0.7167 - val_accuracy: 0.7464\n",
            "Epoch 4/5\n",
            "91/91 [==============================] - 49s 540ms/step - loss: 0.6481 - accuracy: 0.7280 - val_loss: 0.5956 - val_accuracy: 0.7790\n",
            "Epoch 5/5\n",
            "91/91 [==============================] - 49s 537ms/step - loss: 0.5400 - accuracy: 0.7873 - val_loss: 0.5748 - val_accuracy: 0.7899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/Colab Data_Files/Thakur_Data/Log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwRszLt5G-3x",
        "outputId": "10074909-655d-44d3-bea6-6f9d5ca79a60"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Corn**"
      ],
      "metadata": {
        "id": "4a3nn49rxnoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_Corn,val_Corn = Data_Augmentation('Corn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVasBIw_xRY9",
        "outputId": "1efb2f0b-9ec7-41fc-c5c2-92826dd87def"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3473 images belonging to 4 classes.\n",
            "Found 396 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE  = 32\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS = 3\n",
        "input_shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS)\n",
        "n_classes = 4\n",
        "\n",
        "model_Corn = models.Sequential([\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
        "    layers.DepthwiseConv2D(kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_Corn.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "v4dmLrl8H-rN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Corn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Iqz4cedIhij",
        "outputId": "93abdffd-7b10-4c4a-bd70-eb750e6d9093"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " depthwise_conv2d_1 (Depthwi  (None, 252, 252, 32)     320       \n",
            " seConv2D)                                                       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 126, 126, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 124, 124, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 2, 2, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 1, 1, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 208,772\n",
            "Trainable params: 208,772\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_Corn.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "_1ub7TFLNMbr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard = create_tensorboard_callback()\n",
        "\n",
        "history_1 = model_Corn.fit(train_Corn,\n",
        "                        epochs=10,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        verbose=1,\n",
        "                        callbacks=[tensorboard],\n",
        "                        steps_per_epoch=len(train_Corn),\n",
        "                        validation_data=val_Corn,\n",
        "                        validation_steps=len(val_Corn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xptz9dAMlFx",
        "outputId": "837aa66a-dd94-410e-d991-3ce8fed9c8ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "109/109 [==============================] - 785s 7s/step - loss: 1.0923 - accuracy: 0.4794 - val_loss: 0.8429 - val_accuracy: 0.5707\n",
            "Epoch 2/10\n",
            "109/109 [==============================] - 64s 585ms/step - loss: 0.7831 - accuracy: 0.6041 - val_loss: 0.7847 - val_accuracy: 0.5758\n",
            "Epoch 3/10\n",
            "109/109 [==============================] - 64s 585ms/step - loss: 0.7507 - accuracy: 0.6070 - val_loss: 0.7783 - val_accuracy: 0.5758\n",
            "Epoch 4/10\n",
            "109/109 [==============================] - 66s 603ms/step - loss: 0.7529 - accuracy: 0.6090 - val_loss: 0.7741 - val_accuracy: 0.5758\n",
            "Epoch 5/10\n",
            "109/109 [==============================] - 64s 586ms/step - loss: 0.7550 - accuracy: 0.6050 - val_loss: 0.7836 - val_accuracy: 0.5758\n",
            "Epoch 6/10\n",
            "109/109 [==============================] - 65s 591ms/step - loss: 0.7524 - accuracy: 0.6021 - val_loss: 0.7835 - val_accuracy: 0.5758\n",
            "Epoch 7/10\n",
            "109/109 [==============================] - 64s 586ms/step - loss: 0.7456 - accuracy: 0.5992 - val_loss: 0.7779 - val_accuracy: 0.5758\n",
            "Epoch 8/10\n",
            "109/109 [==============================] - 66s 607ms/step - loss: 0.7364 - accuracy: 0.5995 - val_loss: 0.7734 - val_accuracy: 0.5758\n",
            "Epoch 9/10\n",
            "109/109 [==============================] - 64s 586ms/step - loss: 0.7547 - accuracy: 0.6032 - val_loss: 0.8093 - val_accuracy: 0.5758\n",
            "Epoch 10/10\n",
            "109/109 [==============================] - 64s 587ms/step - loss: 0.7439 - accuracy: 0.6058 - val_loss: 0.7779 - val_accuracy: 0.5758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_Corn_1 = models.Sequential([\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_Corn_1.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "Ik1AT8FLeHSQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_Corn_1.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Xw81KLQSeaGT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard = create_tensorboard_callback()\n",
        "\n",
        "history_corn = model_Corn_1.fit(train_Corn,\n",
        "                        epochs=50,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        verbose=1,\n",
        "                        callbacks=[tensorboard],\n",
        "                        steps_per_epoch=len(train_Corn),\n",
        "                        validation_data=val_Corn,\n",
        "                        validation_steps=len(val_Corn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttoxUjiAej7E",
        "outputId": "13d75162-eb00-4617-f20e-0cb7387f2f9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "109/109 [==============================] - 59s 539ms/step - loss: 0.6594 - accuracy: 0.7121 - val_loss: 0.2963 - val_accuracy: 0.8535\n",
            "Epoch 2/50\n",
            "109/109 [==============================] - 56s 511ms/step - loss: 0.3397 - accuracy: 0.8422 - val_loss: 0.6269 - val_accuracy: 0.7626\n",
            "Epoch 3/50\n",
            "109/109 [==============================] - 56s 510ms/step - loss: 0.2991 - accuracy: 0.8534 - val_loss: 0.2640 - val_accuracy: 0.8409\n",
            "Epoch 4/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.3233 - accuracy: 0.8514 - val_loss: 0.2112 - val_accuracy: 0.9167\n",
            "Epoch 5/50\n",
            "109/109 [==============================] - 56s 511ms/step - loss: 0.2560 - accuracy: 0.8727 - val_loss: 0.2149 - val_accuracy: 0.9268\n",
            "Epoch 6/50\n",
            "109/109 [==============================] - 58s 534ms/step - loss: 0.2609 - accuracy: 0.8750 - val_loss: 0.1717 - val_accuracy: 0.9369\n",
            "Epoch 7/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.2733 - accuracy: 0.8727 - val_loss: 0.2250 - val_accuracy: 0.8838\n",
            "Epoch 8/50\n",
            "109/109 [==============================] - 56s 510ms/step - loss: 0.2631 - accuracy: 0.8834 - val_loss: 0.1657 - val_accuracy: 0.9192\n",
            "Epoch 9/50\n",
            "109/109 [==============================] - 56s 510ms/step - loss: 0.2314 - accuracy: 0.8981 - val_loss: 0.1663 - val_accuracy: 0.9343\n",
            "Epoch 10/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.2360 - accuracy: 0.8972 - val_loss: 0.1767 - val_accuracy: 0.9192\n",
            "Epoch 11/50\n",
            "109/109 [==============================] - 58s 534ms/step - loss: 0.2099 - accuracy: 0.9053 - val_loss: 0.1651 - val_accuracy: 0.9369\n",
            "Epoch 12/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.2083 - accuracy: 0.9064 - val_loss: 0.1800 - val_accuracy: 0.9318\n",
            "Epoch 13/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.1949 - accuracy: 0.9174 - val_loss: 0.1216 - val_accuracy: 0.9495\n",
            "Epoch 14/50\n",
            "109/109 [==============================] - 56s 511ms/step - loss: 0.2023 - accuracy: 0.9223 - val_loss: 0.1068 - val_accuracy: 0.9596\n",
            "Epoch 15/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.1834 - accuracy: 0.9315 - val_loss: 0.1021 - val_accuracy: 0.9571\n",
            "Epoch 16/50\n",
            "109/109 [==============================] - 58s 532ms/step - loss: 0.1818 - accuracy: 0.9246 - val_loss: 0.1360 - val_accuracy: 0.9596\n",
            "Epoch 17/50\n",
            "109/109 [==============================] - 55s 508ms/step - loss: 0.1810 - accuracy: 0.9251 - val_loss: 0.1412 - val_accuracy: 0.9343\n",
            "Epoch 18/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.1989 - accuracy: 0.9228 - val_loss: 0.1046 - val_accuracy: 0.9545\n",
            "Epoch 19/50\n",
            "109/109 [==============================] - 56s 510ms/step - loss: 0.1763 - accuracy: 0.9263 - val_loss: 0.0968 - val_accuracy: 0.9621\n",
            "Epoch 20/50\n",
            "109/109 [==============================] - 58s 532ms/step - loss: 0.1600 - accuracy: 0.9344 - val_loss: 0.1207 - val_accuracy: 0.9444\n",
            "Epoch 21/50\n",
            "109/109 [==============================] - 55s 507ms/step - loss: 0.1550 - accuracy: 0.9387 - val_loss: 0.0865 - val_accuracy: 0.9672\n",
            "Epoch 22/50\n",
            "109/109 [==============================] - 56s 510ms/step - loss: 0.1447 - accuracy: 0.9415 - val_loss: 0.1081 - val_accuracy: 0.9444\n",
            "Epoch 23/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.1570 - accuracy: 0.9369 - val_loss: 0.1086 - val_accuracy: 0.9596\n",
            "Epoch 24/50\n",
            "109/109 [==============================] - 56s 511ms/step - loss: 0.1475 - accuracy: 0.9381 - val_loss: 0.0697 - val_accuracy: 0.9747\n",
            "Epoch 25/50\n",
            "109/109 [==============================] - 58s 532ms/step - loss: 0.1548 - accuracy: 0.9390 - val_loss: 0.1064 - val_accuracy: 0.9646\n",
            "Epoch 26/50\n",
            "109/109 [==============================] - 55s 507ms/step - loss: 0.1287 - accuracy: 0.9444 - val_loss: 0.0755 - val_accuracy: 0.9722\n",
            "Epoch 27/50\n",
            "109/109 [==============================] - 56s 511ms/step - loss: 0.1363 - accuracy: 0.9450 - val_loss: 0.0780 - val_accuracy: 0.9773\n",
            "Epoch 28/50\n",
            "109/109 [==============================] - 56s 511ms/step - loss: 0.1281 - accuracy: 0.9508 - val_loss: 0.0743 - val_accuracy: 0.9798\n",
            "Epoch 29/50\n",
            "109/109 [==============================] - 56s 511ms/step - loss: 0.1383 - accuracy: 0.9505 - val_loss: 0.0943 - val_accuracy: 0.9646\n",
            "Epoch 30/50\n",
            "109/109 [==============================] - 59s 538ms/step - loss: 0.1572 - accuracy: 0.9378 - val_loss: 0.1070 - val_accuracy: 0.9722\n",
            "Epoch 31/50\n",
            "109/109 [==============================] - 56s 511ms/step - loss: 0.1321 - accuracy: 0.9496 - val_loss: 0.0656 - val_accuracy: 0.9747\n",
            "Epoch 32/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.1295 - accuracy: 0.9531 - val_loss: 0.0605 - val_accuracy: 0.9823\n",
            "Epoch 33/50\n",
            "109/109 [==============================] - 55s 505ms/step - loss: 0.1296 - accuracy: 0.9516 - val_loss: 0.0718 - val_accuracy: 0.9747\n",
            "Epoch 34/50\n",
            "109/109 [==============================] - 58s 534ms/step - loss: 0.1221 - accuracy: 0.9536 - val_loss: 0.0628 - val_accuracy: 0.9823\n",
            "Epoch 35/50\n",
            "109/109 [==============================] - 56s 510ms/step - loss: 0.1216 - accuracy: 0.9551 - val_loss: 0.0608 - val_accuracy: 0.9773\n",
            "Epoch 36/50\n",
            "109/109 [==============================] - 55s 506ms/step - loss: 0.1397 - accuracy: 0.9490 - val_loss: 0.0708 - val_accuracy: 0.9747\n",
            "Epoch 37/50\n",
            "109/109 [==============================] - 55s 507ms/step - loss: 0.1220 - accuracy: 0.9539 - val_loss: 0.0655 - val_accuracy: 0.9798\n",
            "Epoch 38/50\n",
            "109/109 [==============================] - 57s 526ms/step - loss: 0.1115 - accuracy: 0.9582 - val_loss: 0.0924 - val_accuracy: 0.9621\n",
            "Epoch 39/50\n",
            "109/109 [==============================] - 61s 555ms/step - loss: 0.1130 - accuracy: 0.9582 - val_loss: 0.0479 - val_accuracy: 0.9874\n",
            "Epoch 40/50\n",
            "109/109 [==============================] - 57s 521ms/step - loss: 0.1149 - accuracy: 0.9559 - val_loss: 0.0484 - val_accuracy: 0.9798\n",
            "Epoch 41/50\n",
            "109/109 [==============================] - 56s 517ms/step - loss: 0.1207 - accuracy: 0.9577 - val_loss: 0.0583 - val_accuracy: 0.9798\n",
            "Epoch 42/50\n",
            "109/109 [==============================] - 56s 514ms/step - loss: 0.1111 - accuracy: 0.9600 - val_loss: 0.0573 - val_accuracy: 0.9848\n",
            "Epoch 43/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.1170 - accuracy: 0.9542 - val_loss: 0.0698 - val_accuracy: 0.9823\n",
            "Epoch 44/50\n",
            "109/109 [==============================] - 58s 535ms/step - loss: 0.1083 - accuracy: 0.9585 - val_loss: 0.0472 - val_accuracy: 0.9823\n",
            "Epoch 45/50\n",
            "109/109 [==============================] - 56s 515ms/step - loss: 0.1105 - accuracy: 0.9591 - val_loss: 0.0463 - val_accuracy: 0.9798\n",
            "Epoch 46/50\n",
            "109/109 [==============================] - 56s 512ms/step - loss: 0.1217 - accuracy: 0.9539 - val_loss: 0.0608 - val_accuracy: 0.9823\n",
            "Epoch 47/50\n",
            "109/109 [==============================] - 56s 509ms/step - loss: 0.1031 - accuracy: 0.9585 - val_loss: 0.0617 - val_accuracy: 0.9798\n",
            "Epoch 48/50\n",
            "109/109 [==============================] - 59s 537ms/step - loss: 0.1173 - accuracy: 0.9608 - val_loss: 0.0506 - val_accuracy: 0.9848\n",
            "Epoch 49/50\n",
            "109/109 [==============================] - 56s 512ms/step - loss: 0.1188 - accuracy: 0.9580 - val_loss: 0.0817 - val_accuracy: 0.9747\n",
            "Epoch 50/50\n",
            "109/109 [==============================] - 56s 510ms/step - loss: 0.1020 - accuracy: 0.9660 - val_loss: 0.0558 - val_accuracy: 0.9798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_Corn_1.save('model.h5')"
      ],
      "metadata": {
        "id": "jDEaLKdvs4cV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Grape**"
      ],
      "metadata": {
        "id": "_4kMU2gpyFK_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GizXcOpYyG1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}